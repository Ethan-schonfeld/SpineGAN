{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=(-5, 5)),\n",
    "    transforms.RandomResizedCrop(size=(224,224), scale=(0.8, 1.0), ratio=(1., 1.))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/ethanschonfeld/cs236g/SpineGAN/abnormality_detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_directory = \"/home/ethanschonfeld/cs236g/vindr/annotations/train.csv\"\n",
    "train_image_directory = \"/home/ethanschonfeld/cs236g/SpineGAN/stylegan2-ada-pytorch-main/abnormality_conditional_dataset/\"\n",
    "test_label_directory = \"/home/ethanschonfeld/cs236g/vindr/annotations/test.csv\"\n",
    "test_image_directory = \"/home/ethanschonfeld/cs236g/test_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading in train images and labels\")\n",
    "train_annotations = pd.read_csv(train_label_directory)\n",
    "train_image_file_list = list(os.listdir(train_image_directory))\n",
    "os.chdir(train_image_directory)\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for filename in train_image_file_list:\n",
    "    extension = filename[-4:]\n",
    "    if extension != \".png\":\n",
    "        continue\n",
    "    try:\n",
    "        image = Image.open(filename)\n",
    "        label = np.zeros(8)\n",
    "        for idx_number in train_annotations.index:\n",
    "            if train_annotations.loc[idx_number, \"image_id\"] == filename[:-4]:\n",
    "                lesion_type = train_annotations.loc[idx_number, \"lesion_type\"]\n",
    "                if lesion_type == \"No finding\":\n",
    "                    label[0] = 1\n",
    "                elif lesion_type == \"Disc space narrowing\":\n",
    "                    label[1] = 1\n",
    "                elif lesion_type == \"Foraminal stenosis\":\n",
    "                    label[2] = 1\n",
    "                elif lesion_type == \"Osteophytes\":\n",
    "                    label[3] = 1\n",
    "                elif lesion_type == \"Spondylolysthesis\":\n",
    "                    label[4] = 1\n",
    "                elif lesion_type == \"Surgical implant\":\n",
    "                    label[5] = 1\n",
    "                elif lesion_type == \"Vertebral collapse\":\n",
    "                    label[6] = 1\n",
    "                elif lesion_type == \"Other lesions\":\n",
    "                    label[7] = 1\n",
    "        data = np.asarray(image)\n",
    "        three_channel_data = np.repeat(data[:, :, np.newaxis], 3, axis=2)\n",
    "        train_images.append(three_channel_data)\n",
    "        train_labels.append(label)\n",
    "    except:\n",
    "        print(filename)\n",
    "train_images = np.asarray(train_images)\n",
    "train_labels = np.asarray(train_labels)\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading in test images and labels\")\n",
    "test_annotations = pd.read_csv(test_label_directory)\n",
    "test_image_file_list = list(os.listdir(test_image_directory))\n",
    "os.chdir(test_image_directory)\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for filename in test_image_file_list:\n",
    "    extension = filename[-4:]\n",
    "    if extension != \".png\":\n",
    "        continue\n",
    "    try:\n",
    "        image = Image.open(filename)\n",
    "        label = np.zeros(8)\n",
    "        for idx_number in test_annotations.index:\n",
    "            if test_annotations.loc[idx_number, \"image_id\"] == filename[:-4]:\n",
    "                lesion_type = test_annotations.loc[idx_number, \"lesion_type\"]\n",
    "                if lesion_type == \"No finding\":\n",
    "                    label[0] = 1\n",
    "                elif lesion_type == \"Disc space narrowing\":\n",
    "                    label[1] = 1\n",
    "                elif lesion_type == \"Foraminal stenosis\":\n",
    "                    label[2] = 1\n",
    "                elif lesion_type == \"Osteophytes\":\n",
    "                    label[3] = 1\n",
    "                elif lesion_type == \"Spondylolysthesis\":\n",
    "                    label[4] = 1\n",
    "                elif lesion_type == \"Surgical implant\":\n",
    "                    label[5] = 1\n",
    "                elif lesion_type == \"Vertebral collapse\":\n",
    "                    label[6] = 1\n",
    "                elif lesion_type == \"Other lesions\":\n",
    "                    label[7] = 1\n",
    "        data = np.asarray(image)\n",
    "        three_channel_data = np.repeat(data[:, :, np.newaxis], 3, axis=2)\n",
    "        test_images.append(three_channel_data)\n",
    "        test_labels.append(label)\n",
    "    except:\n",
    "        print(filename)\n",
    "test_images = np.asarray(test_images)\n",
    "test_labels = np.asarray(test_labels)\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_0 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,0]).tolist(), y=train_labels[:,0])\n",
    "class_weights_0 = {i : class_weights_0[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_1 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,1]).tolist(), y=train_labels[:,1])\n",
    "class_weights_1 = {i : class_weights_1[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_2 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,2]).tolist(), y=train_labels[:,2])\n",
    "class_weights_2 = {i : class_weights_2[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_3 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,3]).tolist(), y=train_labels[:,3])\n",
    "class_weights_3 = {i : class_weights_3[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_4 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,4]).tolist(), y=train_labels[:,4])\n",
    "class_weights_4 = {i : class_weights_4[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_5 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,5]).tolist(), y=train_labels[:,5])\n",
    "class_weights_5 = {i : class_weights_5[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_6 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,6]).tolist(), y=train_labels[:,6])\n",
    "class_weights_6 = {i : class_weights_6[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_7 = class_weight.compute_class_weight(\"balanced\", \n",
    "                                                   classes=np.unique(train_labels[:,7]).tolist(), y=train_labels[:,7])\n",
    "class_weights_7 = {i : class_weights_7[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet201(pretrained=True)\n",
    "model = nn.Sequential(\n",
    "    model,\n",
    "    nn.Linear(in_features=1000, out_features=8, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCELoss_class_weighted(weights):\n",
    "\n",
    "    def loss(inputs, target):\n",
    "        inputs = torch.clamp(inputs,min=1e-7,max=1-1e-7)\n",
    "        bce = - weights[1] * target * torch.log(inputs) - (1 - target) * weights[0] * torch.log(1 - inputs)\n",
    "        return torch.mean(bce)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_0 = BCELoss_class_weighted(class_weights_0)\n",
    "criterion_1 = BCELoss_class_weighted(class_weights_1)\n",
    "criterion_2 = BCELoss_class_weighted(class_weights_2)\n",
    "criterion_3 = BCELoss_class_weighted(class_weights_3)\n",
    "criterion_4 = BCELoss_class_weighted(class_weights_4)\n",
    "criterion_5 = BCELoss_class_weighted(class_weights_5)\n",
    "criterion_6 = BCELoss_class_weighted(class_weights_6)\n",
    "criterion_7 = BCELoss_class_weighted(class_weights_7)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hc/mqvqyzcj4wx80t5xmf4_c4380000gn/T/ipykernel_63202/2109919395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# About 42 min per epoch on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_test_auc_estimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "# About 42 min per epoch on CPU\n",
    "batch_size = 32\n",
    "num_batches = math.ceil(train_images.shape[0]/batch_size)\n",
    "best_test_auc_estimate = 0\n",
    "\n",
    "for i in range(0, 10000): # they used 10000\n",
    "    epoch_loss = 0.0\n",
    "    epoch_auc_estimation_0 = []\n",
    "    epoch_auc_estimation_1 = []\n",
    "    epoch_auc_estimation_2 = []\n",
    "    epoch_auc_estimation_3 = []\n",
    "    epoch_auc_estimation_4 = []\n",
    "    epoch_auc_estimation_5 = []\n",
    "    epoch_auc_estimation_6 = []\n",
    "    epoch_auc_estimation_7 = []\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch_num % 5 == 0:\n",
    "            print(\"Epoch: \", i, \" Batch: \", batch_num)\n",
    "            \n",
    "        batch = train_images[batch_num*batch_size:(batch_num+1)*batch_size, :, :, :]\n",
    "        batch_labels = train_labels[batch_num*batch_size:(batch_num+1)*batch_size]\n",
    "        batch_labels = torch.Tensor(batch_labels)\n",
    "        \n",
    "        train_X = torch.empty(0, 3, 224, 224)\n",
    "        for image_number in range(batch.shape[0]):\n",
    "            tensor = preprocess(Image.fromarray(batch[image_number, :, :, :]))\n",
    "            tensor = tensor.unsqueeze(0)\n",
    "            train_X = torch.cat([train_X, tensor], dim=0)\n",
    "        if torch.cuda.is_available():\n",
    "            train_X.to('cuda')\n",
    "            \n",
    "        # augment the images according to the augmentation defined above\n",
    "        train_X = transform_augment(train_X).to('cuda')\n",
    "            \n",
    "        outputs = model(train_X).to('cuda')\n",
    "        loss_0 = criterion(outputs[:,0].to('cuda'), batch_labels[:,0].unsqueeze(1).to('cuda'))\n",
    "        loss_1 = criterion(outputs[:,1].to('cuda'), batch_labels[:,1].unsqueeze(1).to('cuda'))\n",
    "        loss_2 = criterion(outputs[:,2].to('cuda'), batch_labels[:,2].unsqueeze(1).to('cuda'))\n",
    "        loss_3 = criterion(outputs[:,3].to('cuda'), batch_labels[:,3].unsqueeze(1).to('cuda'))\n",
    "        loss_4 = criterion(outputs[:,4].to('cuda'), batch_labels[:,4].unsqueeze(1).to('cuda'))\n",
    "        loss_5 = criterion(outputs[:,5].to('cuda'), batch_labels[:,5].unsqueeze(1).to('cuda'))\n",
    "        loss_6 = criterion(outputs[:,6].to('cuda'), batch_labels[:,6].unsqueeze(1).to('cuda'))\n",
    "        loss_7 = criterion(outputs[:,7].to('cuda'), batch_labels[:,7].unsqueeze(1).to('cuda'))\n",
    "        loss = loss_0+loss_1+loss_2+loss_3+loss_4+loss_5+loss_6+loss_7\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_auc_0 = roc_auc_score(batch_labels[:,0].cpu().detach().numpy(), outputs[:,0].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_0.append(train_auc_0)\n",
    "        train_auc_1 = roc_auc_score(batch_labels[:,1].cpu().detach().numpy(), outputs[:,1].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_1.append(train_auc_1)\n",
    "        train_auc_2 = roc_auc_score(batch_labels[:,2].cpu().detach().numpy(), outputs[:,2].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_2.append(train_auc_2)\n",
    "        train_auc_3 = roc_auc_score(batch_labels[:,3].cpu().detach().numpy(), outputs[:,3].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_3.append(train_auc_3)\n",
    "        train_auc_4 = roc_auc_score(batch_labels[:,4].cpu().detach().numpy(), outputs[:,4].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_4.append(train_auc_4)\n",
    "        train_auc_5 = roc_auc_score(batch_labels[:,5].cpu().detach().numpy(), outputs[:,5].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_5.append(train_auc_5)\n",
    "        train_auc_6 = roc_auc_score(batch_labels[:,6].cpu().detach().numpy(), outputs[:,6].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_6.append(train_auc_6)\n",
    "        train_auc_7 = roc_auc_score(batch_labels[:,7].cpu().detach().numpy(), outputs[:,7].cpu().detach().numpy())\n",
    "        epoch_auc_estimation_7.append(train_auc_7)\n",
    "        \n",
    "    print(\"Epoch \", i, \" Train AUC estimation No finding: \", sum(epoch_auc_estimation_0)/len(epoch_auc_estimation_0))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Disc space narrowing: \", sum(epoch_auc_estimation_1)/len(epoch_auc_estimation_1))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Foraminal stenosis: \", sum(epoch_auc_estimation_2)/len(epoch_auc_estimation_2))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Osteophytes: \", sum(epoch_auc_estimation_3)/len(epoch_auc_estimation_3))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Spondylolysthesis: \", sum(epoch_auc_estimation_4)/len(epoch_auc_estimation_4))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Surgical implant: \", sum(epoch_auc_estimation_5)/len(epoch_auc_estimation_5))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Vertebral collapse: \", sum(epoch_auc_estimation_6)/len(epoch_auc_estimation_6))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Other lesions: \", sum(epoch_auc_estimation_7)/len(epoch_auc_estimation_7))\n",
    "    print(\"Epoch \", i, \" Train AUC estimation Average: \", (sum(epoch_auc_estimation_0)+sum(epoch_auc_estimation_1)+sum(epoch_auc_estimation_2)+sum(epoch_auc_estimation_3)+sum(epoch_auc_estimation_4)+sum(epoch_auc_estimation_5)+sum(epoch_auc_estimation_6)+sum(epoch_auc_estimation_7))/len(epoch_auc_estimation_0)*8)\n",
    "\n",
    "                \n",
    "    print(\"Epoch \", i, \" loss: \", epoch_loss)\n",
    "    # get random sample of 600 of test images\n",
    "    total_num_test = int(test_images.shape[0])\n",
    "    # sample 600 without replacement\n",
    "    total_num_test = range(total_num_test)\n",
    "    random_sample = random.sample(total_num_test, 600)\n",
    "    test_batch = test_images[random_sample, :, :, :]\n",
    "    test_batch_labels = [test_labels[i] for i in random_sample]\n",
    "    test_batch_labels = torch.Tensor(test_batch_labels)\n",
    "    \n",
    "    test_X = torch.empty(0, 3, 224, 224)\n",
    "    for image_number in range(test_batch.shape[0]):\n",
    "        tensor = preprocess(Image.fromarray(test_batch[image_number, :, :, :]))\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        test_X = torch.cat([test_X, tensor], dim=0)\n",
    "    if torch.cuda.is_available():\n",
    "        test_X.to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_X.to('cuda'))\n",
    "        print(\"AUC No Finding: \")\n",
    "        test_auc_0 = roc_auc_score(test_batch_labels[:,0].cpu().detach().numpy(), test_outputs[:,0].cpu().detach().numpy())\n",
    "        print(test_auc_0)\n",
    "        \n",
    "        print(\"AUC Disc space narrowing: \")\n",
    "        test_auc_1 = roc_auc_score(test_batch_labels[:,1].cpu().detach().numpy(), test_outputs[:,1].cpu().detach().numpy())\n",
    "        print(test_auc_1)\n",
    "        \n",
    "        print(\"Foraminal stenosis: \")\n",
    "        test_auc_2 = roc_auc_score(test_batch_labels[:,2].cpu().detach().numpy(), test_outputs[:,2].cpu().detach().numpy())\n",
    "        print(test_auc_2)\n",
    "        \n",
    "        print(\"AUC Osteophytes: \")\n",
    "        test_auc_3 = roc_auc_score(test_batch_labels[:,3].cpu().detach().numpy(), test_outputs[:,3].cpu().detach().numpy())\n",
    "        print(test_auc_3)\n",
    "        \n",
    "        print(\"AUC Spondylolysthesis: \")\n",
    "        test_auc_4 = roc_auc_score(test_batch_labels[:,4].cpu().detach().numpy(), test_outputs[:,4].cpu().detach().numpy())\n",
    "        print(test_auc_4)\n",
    "        \n",
    "        print(\"AUC Surgical implant: \")\n",
    "        test_auc_5 = roc_auc_score(test_batch_labels[:,5].cpu().detach().numpy(), test_outputs[:,5].cpu().detach().numpy())\n",
    "        print(test_auc_5)\n",
    "        \n",
    "        print(\"AUC Vertebral collapse: \")\n",
    "        test_auc_6 = roc_auc_score(test_batch_labels[:,6].cpu().detach().numpy(), test_outputs[:,6].cpu().detach().numpy())\n",
    "        print(test_auc_6)\n",
    "        \n",
    "        print(\"AUC Other lesions: \")\n",
    "        test_auc_7 = roc_auc_score(test_batch_labels[:,7].cpu().detach().numpy(), test_outputs[:,7].cpu().detach().numpy())\n",
    "        print(test_auc_7)\n",
    "        \n",
    "    print(\"Epoch \", i, \" Test Sample AUC: \", (test_auc_0+test_auc_1+test_auc_2+test_auc_3+test_auc_4+test_auc_5+test_auc_6+test_auc_7)/8)\n",
    "    torch.save(model, checkpoint_path+\"checkpoint_cond_aug_\"+str(i)+\".pt\")\n",
    "    if test_auc > best_test_auc_estimate:\n",
    "        best_test_auc_estimate = test_auc\n",
    "    #    torch.save(model, checkpoint_path+\"checkpoint_aug_\"+str(i)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
